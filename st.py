import streamlit as st
import os, sys
from core.st_utils.imports_and_utils import *
from core import *
# Reduce torchaudio deprecation warnings in logs
os.environ.setdefault("TORCHAUDIO_USE_BACKEND_DISPATCHER", "1")
from core.utils.config_utils import load_key

# SET PATH
current_dir = os.path.dirname(os.path.abspath(__file__))
os.environ['PATH'] += os.pathsep + current_dir
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

st.set_page_config(page_title="VideoLingo", page_icon="docs/logo.svg")

SUB_VIDEO = "output/output_sub.mp4"
DUB_VIDEO = "output/output_dub.mp4"
ASR_TIMELINE_EXCEL = "output/log/cleaned_chunks.xlsx"
ASR_SRT_PATH = "output/asr_only.srt"

def text_processing_section():
    st.header(t("b. Translate and Generate Subtitles"))
    with st.container(border=True):
        st.markdown(f"""
        <p style='font-size: 20px;'>
        {t("This stage includes the following steps:")}
        <p style='font-size: 20px;'>
            1. {t("WhisperX word-level transcription")}<br>
            2. {t("Sentence segmentation using NLP and LLM")}<br>
            3. {t("Summarization and multi-step translation")}<br>
            4. {t("Cutting and aligning long subtitles")}<br>
            5. {t("Generating timeline and subtitles")}<br>
            6. {t("Merging subtitles into the video")}
        """, unsafe_allow_html=True)

        if not os.path.exists(SUB_VIDEO):
            if st.button(t("Start Processing Subtitles"), key="text_processing_button"):
                process_text()
                st.rerun()
        else:
            if load_key("burn_subtitles"):
                st.video(SUB_VIDEO)
            download_subtitle_zip_button(text=t("Download All Srt Files"))
            
            if st.button(t("Archive to 'history'"), key="cleanup_in_text_processing"):
                cleanup()
                st.rerun()
            return True

def process_text():
    with st.spinner(t("Using Whisper for transcription...")):
        _2_asr.transcribe()
    with st.spinner(t("Splitting long sentences...")):  
        _3_1_split_nlp.split_by_spacy()
        _3_2_split_meaning.split_sentences_by_meaning()
    with st.spinner(t("Summarizing and translating...")):
        _4_1_summarize.get_summary()
        if load_key("pause_before_translate"):
            input(t("âš ï¸ PAUSE_BEFORE_TRANSLATE. Go to `output/log/terminology.json` to edit terminology. Then press ENTER to continue..."))
        _4_2_translate.translate_all()
    with st.spinner(t("Processing and aligning subtitles...")): 
        _5_split_sub.split_for_sub_main()
        _6_gen_sub.align_timestamp_main()
    with st.spinner(t("Merging subtitles to video...")):
        _7_sub_into_vid.merge_subtitles_to_video()
    
    st.success(t("Subtitle processing complete! ğŸ‰"))
    st.balloons()

def audio_processing_section():
    st.header(t("c. Dubbing"))
    with st.container(border=True):
        st.markdown(f"""
        <p style='font-size: 20px;'>
        {t("This stage includes the following steps:")}
        <p style='font-size: 20px;'>
            1. {t("Generate audio tasks and chunks")}<br>
            2. {t("Extract reference audio")}<br>
            3. {t("Generate and merge audio files")}<br>
            4. {t("Merge final audio into video")}
        """, unsafe_allow_html=True)
        if not os.path.exists(DUB_VIDEO):
            if st.button(t("Start Audio Processing"), key="audio_processing_button"):
                process_audio()
                st.rerun()
        else:
            st.success(t("Audio processing is complete! You can check the audio files in the `output` folder."))
            if load_key("burn_subtitles"):
                st.video(DUB_VIDEO) 
            if st.button(t("Delete dubbing files"), key="delete_dubbing_files"):
                delete_dubbing_files()
                st.rerun()
            if st.button(t("Archive to 'history'"), key="cleanup_in_audio_processing"):
                cleanup()
                st.rerun()

def process_audio():
    with st.spinner(t("Generate audio tasks")): 
        _8_1_audio_task.gen_audio_task_main()
        _8_2_dub_chunks.gen_dub_chunks()
    with st.spinner(t("Extract refer audio")):
        _9_refer_audio.extract_refer_audio_main()
    with st.spinner(t("Generate all audio")):
        _10_gen_audio.gen_audio()
    with st.spinner(t("Merge full audio")):
        _11_merge_audio.merge_full_audio()
    with st.spinner(t("Merge dubbing to the video")):
        _12_dub_to_vid.merge_video_audio()
    
    st.success(t("Audio processing complete! ğŸ‡"))
    st.balloons()

def asr_only_section():
    st.header(t("a. ä»…è¿›è¡Œ ASR è¯†åˆ«"))
    with st.container(border=True):
        st.markdown(t("ä»…å¯¹åŸè§†é¢‘è¿›è¡Œ WhisperX è¯†åˆ«ï¼Œå¯¼å‡ºæ ‡å‡† SRT å­—å¹•æ–‡ä»¶ï¼›ä¸è¿›è¡Œåˆ†å¥ã€ç¿»è¯‘æˆ–é…éŸ³ã€‚è¯†åˆ«å®Œæˆåä¼šæ˜¾ç¤ºå®Œæˆæ ‡è®°ä¸ä¸‹è½½æŒ‰é’®ã€‚"))

        col1, col2 = st.columns(2)
        with col1:
            if st.button(t("å¼€å§‹ä»… ASR è¯†åˆ«"), key="asr_only_button_start"):
                with st.spinner(t("æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œè¯·ç¨å€™â€¦")):
                    step2_whisperX.transcribe(force=True)
                st.success(t("è¯†åˆ«å®Œæˆï¼å¯ä¸‹è½½ SRT æ–‡ä»¶ã€‚"))
                st.rerun()
        with col2:
            if st.button(t("é‡æ–°æ‰§è¡Œ ASR"), key="asr_only_button_rerun"):
                with st.spinner(t("æ­£åœ¨é‡æ–°è¯†åˆ«ï¼Œè¯·ç¨å€™â€¦")):
                    step2_whisperX.transcribe(force=True)
                st.success(t("å·²é‡æ–°è¯†åˆ«ï¼å¯ä¸‹è½½æœ€æ–° SRT æ–‡ä»¶ã€‚"))
                st.rerun()

        if os.path.exists(ASR_SRT_PATH):
            with open(ASR_SRT_PATH, "rb") as f:
                srt_bytes = f.read()
            # çŠ¶æ€ä¸ç»Ÿè®¡
            try:
                import datetime
                mtime = os.path.getmtime(ASR_SRT_PATH)
                ts_str = datetime.datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')
                # ä¼°ç®—å­—å¹•æ¡æ•°ï¼ˆä»¥ç©ºè¡Œåˆ†å‰²ï¼‰
                txt = srt_bytes.decode('utf-8', errors='ignore')
                cues = [blk for blk in txt.strip().split('\n\n') if blk.strip()]
                st.success(t(f"ASR å·²å®Œæˆï¼Œå…± {len(cues)} æ¡å­—å¹•ï¼Œå®Œæˆæ—¶é—´ï¼š{ts_str}"))
            except Exception:
                st.success(t("ASR å·²å®Œæˆï¼Œå¯ä¸‹è½½ SRT æ–‡ä»¶ã€‚"))

            st.download_button(
                label=t("ä¸‹è½½ ASR æ—¶é—´è½´ï¼ˆ.srtï¼‰"),
                data=srt_bytes,
                file_name="asr_timeline.srt",
                mime="application/x-subrip",
            )
        else:
            st.info(t("æš‚æ— å¯ä¸‹è½½çš„ SRT æ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œ ASRã€‚"))

def main():
    logo_col, _ = st.columns([1,1])
    with logo_col:
        st.image("docs/logo.png", use_column_width=True)
    st.markdown(button_style, unsafe_allow_html=True)
    welcome_text = t("Hello, welcome to VideoLingo. If you encounter any issues, feel free to get instant answers with our Free QA Agent <a href=\"https://share.fastgpt.in/chat/share?shareId=066w11n3r9aq6879r4z0v9rh\" target=\"_blank\">here</a>! You can also try out our SaaS website at <a href=\"https://videolingo.io\" target=\"_blank\">videolingo.io</a> for free!")
    st.markdown(f"<p style='font-size: 20px; color: #808080;'>{welcome_text}</p>", unsafe_allow_html=True)
    # add settings
    with st.sidebar:
        page_setting()
        st.markdown(give_star_button, unsafe_allow_html=True)
    download_video_section()
    asr_only_section()
    text_processing_section()
    audio_processing_section()

if __name__ == "__main__":
    main()
